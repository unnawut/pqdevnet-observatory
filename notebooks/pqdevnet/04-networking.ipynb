{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networking\n",
    "\n",
    "P2P networking analysis for PQ Devnet clients.\n",
    "\n",
    "This notebook examines:\n",
    "- Peer connections over time\n",
    "- Peer connection and disconnection events\n",
    "- Attestation arrivals (valid vs invalid, by source)\n",
    "- Network bandwidth per client (rx/tx throughput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters - injected by papermill\n",
    "devnet_id = None  # e.g., \"pqdevnet-20260203T0100Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import display\n",
    "\n",
    "# Set default renderer for static HTML output\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve devnet_id\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "if devnet_id is None:\n",
    "    # Use latest devnet from manifest\n",
    "    devnets_path = DATA_DIR / \"devnets.json\"\n",
    "    if devnets_path.exists():\n",
    "        with open(devnets_path) as f:\n",
    "            devnets = json.load(f).get(\"devnets\", [])\n",
    "        if devnets:\n",
    "            devnet_id = devnets[-1][\"id\"]  # Latest\n",
    "            print(f\"Using latest devnet: {devnet_id}\")\n",
    "    else:\n",
    "        raise ValueError(\"No devnets.json found. Run 'just detect-devnets' first.\")\n",
    "\n",
    "DEVNET_DIR = DATA_DIR / devnet_id\n",
    "print(f\"Loading data from: {DEVNET_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load devnet metadata\n",
    "with open(DATA_DIR / \"devnets.json\") as f:\n",
    "    devnets_data = json.load(f)\n",
    "    devnet_info = next((d for d in devnets_data[\"devnets\"] if d[\"id\"] == devnet_id), None)\n",
    "\n",
    "if devnet_info:\n",
    "    print(f\"Devnet: {devnet_info['id']}\")\n",
    "    print(f\"Duration: {devnet_info['duration_hours']:.1f} hours\")\n",
    "    print(f\"Time: {devnet_info['start_time']} to {devnet_info['end_time']}\")\n",
    "    print(f\"Slots: {devnet_info['start_slot']} \\u2192 {devnet_info['end_slot']}\")\n",
    "    print(f\"Clients: {', '.join(devnet_info['clients'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load network peer data\n",
    "peers_df = pd.read_parquet(DEVNET_DIR / \"network_peers.parquet\")\n",
    "peers_df = peers_df.groupby([\"client\", \"timestamp\"], as_index=False)[\"value\"].max()\n",
    "print(f\"Peers: {len(peers_df)} records, clients: {sorted(peers_df['client'].unique())}\")\n",
    "\n",
    "# Load peer connection/disconnection events\n",
    "peer_events_path = DEVNET_DIR / \"peer_events.parquet\"\n",
    "if peer_events_path.exists():\n",
    "    peer_events_df = pd.read_parquet(peer_events_path)\n",
    "    peer_events_df = peer_events_df.groupby([\"client\", \"metric\", \"timestamp\"], as_index=False)[\"value\"].max()\n",
    "    print(f\"Peer events: {len(peer_events_df)} records, clients: {sorted(peer_events_df['client'].unique())}\")\n",
    "else:\n",
    "    peer_events_df = pd.DataFrame()\n",
    "    print(\"Peer events: no data\")\n",
    "\n",
    "# Load attestation metrics\n",
    "att_df = pd.read_parquet(DEVNET_DIR / \"attestation_metrics.parquet\")\n",
    "att_df = att_df.groupby([\"client\", \"metric\", \"source\", \"timestamp\"], as_index=False)[\"value\"].max()\n",
    "print(f\"Attestations: {len(att_df)} records, clients: {sorted(att_df['client'].unique())}\")\n",
    "print(f\"Attestation metrics: {sorted(att_df['metric'].unique())}\")\n",
    "print(f\"Attestation sources: {sorted(att_df['source'].unique())}\")\n",
    "\n",
    "# Load network throughput (container-level)\n",
    "EXCLUDED_CONTAINERS = {\"unknown\", \"cadvisor\", \"prometheus\", \"promtail\", \"node-exporter\", \"node_exporter\", \"grafana\"}\n",
    "net_path = DEVNET_DIR / \"container_network.parquet\"\n",
    "if net_path.exists():\n",
    "    net_df = pd.read_parquet(net_path)\n",
    "    net_df = net_df[~net_df[\"container\"].isin(EXCLUDED_CONTAINERS)]\n",
    "    net_df = net_df.groupby([\"container\", \"metric\", \"timestamp\"], as_index=False)[\"value\"].sum()\n",
    "    print(f\"Network throughput: {len(net_df)} records, containers: {sorted(net_df['container'].unique())}\")\n",
    "else:\n",
    "    net_df = pd.DataFrame()\n",
    "    print(\"Network throughput: no data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peer Connections\n",
    "\n",
    "Number of connected P2P peers over time. More peers generally means better attestation propagation and network resilience. Drops to 0 or 1 may indicate connectivity issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = sorted(peers_df[\"client\"].unique())\n",
    "\n",
    "if not clients:\n",
    "    print(\"No peer data available\")\n",
    "else:\n",
    "    n_cols = min(len(clients), 2)\n",
    "    n_rows = -(-len(clients) // n_cols)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=n_rows, cols=n_cols,\n",
    "        subplot_titles=clients,\n",
    "        vertical_spacing=0.12 / max(n_rows - 1, 1) * 2,\n",
    "        horizontal_spacing=0.08,\n",
    "    )\n",
    "\n",
    "    for i, client in enumerate(clients):\n",
    "        row = i // n_cols + 1\n",
    "        col = i % n_cols + 1\n",
    "        cdf = peers_df[peers_df[\"client\"] == client].sort_values(\"timestamp\")\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=cdf[\"timestamp\"], y=cdf[\"value\"],\n",
    "                name=client, showlegend=False,\n",
    "                line=dict(color=\"#636EFA\"),\n",
    "            ),\n",
    "            row=row, col=col,\n",
    "        )\n",
    "        fig.update_yaxes(title_text=\"Peers\", row=row, col=col)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Connected Peers Over Time\",\n",
    "        height=270 * n_rows,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peer Connection & Disconnection Events\n",
    "\n",
    "Connection and disconnection events per minute. Spikes in disconnections may indicate network instability or incompatible peers being dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if peer_events_df.empty:\n",
    "    print(\"No peer event data available\")\n",
    "else:\n",
    "    ev_clients = sorted(peer_events_df[\"client\"].unique())\n",
    "    n_cols = min(len(ev_clients), 2)\n",
    "    n_rows = -(-len(ev_clients) // n_cols)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=n_rows, cols=n_cols,\n",
    "        subplot_titles=ev_clients,\n",
    "        vertical_spacing=0.12 / max(n_rows - 1, 1) * 2,\n",
    "        horizontal_spacing=0.08,\n",
    "    )\n",
    "\n",
    "    colors = {\"connection\": \"#00CC96\", \"disconnection\": \"#EF553B\"}\n",
    "    legend_added = set()\n",
    "\n",
    "    for i, client in enumerate(ev_clients):\n",
    "        row = i // n_cols + 1\n",
    "        col = i % n_cols + 1\n",
    "        cdf = peer_events_df[peer_events_df[\"client\"] == client]\n",
    "        for metric in [\"connection\", \"disconnection\"]:\n",
    "            mdf = cdf[cdf[\"metric\"] == metric].sort_values(\"timestamp\").copy()\n",
    "            if mdf.empty:\n",
    "                continue\n",
    "            # Diff the cumulative counter to get per-minute rate\n",
    "            mdf[\"rate\"] = mdf[\"value\"].diff()\n",
    "            # Drop first row (no previous value) and counter resets (negative diffs)\n",
    "            mdf = mdf[(mdf[\"rate\"] >= 0) & mdf[\"rate\"].notna()]\n",
    "            if mdf.empty:\n",
    "                continue\n",
    "            show_legend = metric not in legend_added\n",
    "            legend_added.add(metric)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=mdf[\"timestamp\"], y=mdf[\"rate\"],\n",
    "                    name=metric, legendgroup=metric,\n",
    "                    showlegend=show_legend,\n",
    "                    line=dict(color=colors[metric]),\n",
    "                ),\n",
    "                row=row, col=col,\n",
    "            )\n",
    "        fig.update_yaxes(title_text=\"Events/min\", row=row, col=col)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Peer Connection & Disconnection Events by Client\",\n",
    "        height=270 * n_rows,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attestation Arrivals\n",
    "\n",
    "Cumulative valid and invalid attestations received per client. Attestations arrive via two channels:\n",
    "- **gossip**: received directly from peers over the P2P network\n",
    "- **block**: included in received blocks\n",
    "\n",
    "High invalid counts may indicate signature verification failures or incompatible messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_clients = sorted(att_df[\"client\"].unique())\n",
    "\n",
    "if not att_clients:\n",
    "    print(\"No attestation data available\")\n",
    "else:\n",
    "    n_cols = min(len(att_clients), 2)\n",
    "    n_rows = -(-len(att_clients) // n_cols)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=n_rows, cols=n_cols,\n",
    "        subplot_titles=att_clients,\n",
    "        vertical_spacing=0.12 / max(n_rows - 1, 1) * 2,\n",
    "        horizontal_spacing=0.08,\n",
    "    )\n",
    "\n",
    "    colors = {\n",
    "        (\"valid\", \"gossip\"): \"#636EFA\",\n",
    "        (\"valid\", \"block\"): \"#00CC96\",\n",
    "        (\"valid\", \"unknown\"): \"#AB63FA\",\n",
    "        (\"invalid\", \"gossip\"): \"#EF553B\",\n",
    "        (\"invalid\", \"block\"): \"#FFA15A\",\n",
    "        (\"invalid\", \"unknown\"): \"#FF6692\",\n",
    "    }\n",
    "    legend_added = set()\n",
    "\n",
    "    for i, client in enumerate(att_clients):\n",
    "        row = i // n_cols + 1\n",
    "        col = i % n_cols + 1\n",
    "        cdf = att_df[att_df[\"client\"] == client]\n",
    "\n",
    "        for metric in [\"lean_attestations_valid_total\", \"lean_attestations_invalid_total\"]:\n",
    "            mdf = cdf[cdf[\"metric\"] == metric]\n",
    "            validity = \"valid\" if \"valid\" in metric else \"invalid\"\n",
    "            for source in sorted(mdf[\"source\"].unique()):\n",
    "                sdf = mdf[mdf[\"source\"] == source].sort_values(\"timestamp\")\n",
    "                if sdf.empty or sdf[\"value\"].max() == 0:\n",
    "                    continue\n",
    "                # Insert None at counter resets to break the line\n",
    "                resets = sdf[\"value\"].diff() < 0\n",
    "                if resets.any():\n",
    "                    rows = []\n",
    "                    for idx, is_reset in resets.items():\n",
    "                        if is_reset:\n",
    "                            rows.append({\"timestamp\": sdf.loc[idx, \"timestamp\"], \"value\": None})\n",
    "                        rows.append(sdf.loc[idx].to_dict())\n",
    "                    sdf = pd.DataFrame(rows)\n",
    "                key = (validity, source)\n",
    "                label = f\"{validity} ({source})\"\n",
    "                show_legend = key not in legend_added\n",
    "                legend_added.add(key)\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=sdf[\"timestamp\"], y=sdf[\"value\"],\n",
    "                        name=label, legendgroup=label,\n",
    "                        showlegend=show_legend,\n",
    "                        line=dict(color=colors.get(key, \"#636EFA\")),\n",
    "                        connectgaps=False,\n",
    "                    ),\n",
    "                    row=row, col=col,\n",
    "                )\n",
    "        fig.update_yaxes(title_text=\"Count\", row=row, col=col)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Attestation Counts by Client\",\n",
    "        height=270 * n_rows,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attestation summary: final counts per client\n",
    "att_summary_rows = []\n",
    "\n",
    "for client in att_clients:\n",
    "    row_data = {\"Client\": client}\n",
    "    cdf = att_df[att_df[\"client\"] == client]\n",
    "\n",
    "    for metric in [\"lean_attestations_valid_total\", \"lean_attestations_invalid_total\"]:\n",
    "        mdf = cdf[cdf[\"metric\"] == metric]\n",
    "        validity = \"Valid\" if \"valid\" in metric else \"Invalid\"\n",
    "        for source in sorted(mdf[\"source\"].unique()):\n",
    "            sdf = mdf[mdf[\"source\"] == source]\n",
    "            if not sdf.empty:\n",
    "                col_name = f\"{validity} ({source})\"\n",
    "                row_data[col_name] = f\"{sdf['value'].max():.0f}\"\n",
    "\n",
    "    att_summary_rows.append(row_data)\n",
    "\n",
    "if att_summary_rows:\n",
    "    att_summary = pd.DataFrame(att_summary_rows).set_index(\"Client\").fillna(\"-\")\n",
    "    display(att_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attestation Counts per Slot\n",
    "\n",
    "Estimated attestations received per slot (4 seconds). Computed by diffing cumulative counters at each 1-minute scrape interval and dividing by 15 (slots per minute). Shows combined valid attestations across all sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOT_DURATION = 4  # seconds\n",
    "SLOTS_PER_MINUTE = 60 / SLOT_DURATION\n",
    "\n",
    "# Sum valid attestations across all sources per client per timestamp\n",
    "valid_att = att_df[att_df[\"metric\"] == \"lean_attestations_valid_total\"].copy()\n",
    "valid_per_client = valid_att.groupby([\"client\", \"timestamp\"], as_index=False)[\"value\"].sum()\n",
    "\n",
    "rate_clients = sorted(valid_per_client[\"client\"].unique())\n",
    "\n",
    "if not rate_clients:\n",
    "    print(\"No valid attestation data for rate calculation\")\n",
    "else:\n",
    "    n_cols = min(len(rate_clients), 2)\n",
    "    n_rows = -(-len(rate_clients) // n_cols)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=n_rows, cols=n_cols,\n",
    "        subplot_titles=rate_clients,\n",
    "        vertical_spacing=0.12 / max(n_rows - 1, 1) * 2,\n",
    "        horizontal_spacing=0.08,\n",
    "    )\n",
    "\n",
    "    for i, client in enumerate(rate_clients):\n",
    "        row = i // n_cols + 1\n",
    "        col = i % n_cols + 1\n",
    "        cdf = valid_per_client[valid_per_client[\"client\"] == client].sort_values(\"timestamp\").copy()\n",
    "        # Diff cumulative counter and compute per-slot rate\n",
    "        cdf[\"delta\"] = cdf[\"value\"].diff()\n",
    "        cdf[\"dt\"] = cdf[\"timestamp\"].diff().dt.total_seconds()\n",
    "        # Drop first row, counter resets, and zero-duration intervals\n",
    "        cdf = cdf[(cdf[\"delta\"] >= 0) & (cdf[\"dt\"] > 0) & cdf[\"delta\"].notna()]\n",
    "        if cdf.empty:\n",
    "            continue\n",
    "        cdf[\"per_slot\"] = cdf[\"delta\"] / (cdf[\"dt\"] / SLOT_DURATION)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=cdf[\"timestamp\"], y=cdf[\"per_slot\"],\n",
    "                name=client, showlegend=False,\n",
    "                line=dict(color=\"#636EFA\"),\n",
    "            ),\n",
    "            row=row, col=col,\n",
    "        )\n",
    "        fig.update_yaxes(title_text=\"Atts/slot\", row=row, col=col)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Valid Attestations Received per Slot by Client\",\n",
    "        height=270 * n_rows,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Bandwidth\n",
    "\n",
    "Receive (rx) and transmit (tx) throughput per client container. Dashed horizontal lines show [EIP-7870](https://eips.ethereum.org/EIPS/eip-7870) recommended bandwidth tiers at 15, 25, and 50 Mbps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if net_df.empty:\n",
    "    print(\"No network throughput data available\")\n",
    "else:\n",
    "    # EIP-7870 bandwidth tiers (Mbps -> KB/s)\n",
    "    def mbps_to_kbps(mbps: float) -> float:\n",
    "        return mbps * 1e6 / 8 / 1024\n",
    "\n",
    "    EIP7870_TIERS = [15, 25, 50]  # Mbps\n",
    "\n",
    "    # Filter to client containers only (ending in _0)\n",
    "    client_net = net_df[net_df[\"container\"].str.endswith(\"_0\")].copy()\n",
    "    client_net[\"value_kb\"] = client_net[\"value\"] / 1024\n",
    "\n",
    "    containers = sorted(client_net[\"container\"].unique())\n",
    "    n_cols = min(len(containers), 2)\n",
    "    n_rows = -(-len(containers) // n_cols)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=n_rows, cols=n_cols,\n",
    "        subplot_titles=containers,\n",
    "        vertical_spacing=0.12 / max(n_rows - 1, 1) * 2,\n",
    "        horizontal_spacing=0.08,\n",
    "    )\n",
    "\n",
    "    colors = {\"rx\": \"#636EFA\", \"tx\": \"#EF553B\"}\n",
    "    legend_added = set()\n",
    "\n",
    "    for i, container in enumerate(containers):\n",
    "        row = i // n_cols + 1\n",
    "        col = i % n_cols + 1\n",
    "        cdf = client_net[client_net[\"container\"] == container]\n",
    "        for metric in [\"rx\", \"tx\"]:\n",
    "            mdf = cdf[cdf[\"metric\"] == metric].sort_values(\"timestamp\")\n",
    "            if mdf.empty:\n",
    "                continue\n",
    "            show_legend = metric not in legend_added\n",
    "            legend_added.add(metric)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=mdf[\"timestamp\"], y=mdf[\"value_kb\"],\n",
    "                    name=metric, legendgroup=metric,\n",
    "                    showlegend=show_legend,\n",
    "                    line=dict(color=colors[metric]),\n",
    "                ),\n",
    "                row=row, col=col,\n",
    "            )\n",
    "\n",
    "        # Add EIP-7870 reference lines\n",
    "        for mbps in EIP7870_TIERS:\n",
    "            fig.add_hline(\n",
    "                y=mbps_to_kbps(mbps),\n",
    "                row=row, col=col,\n",
    "                line=dict(color=\"#888\", dash=\"dash\", width=1),\n",
    "                annotation=dict(\n",
    "                    text=f\"{mbps} Mbps\",\n",
    "                    font=dict(size=9, color=\"#888\"),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        fig.update_yaxes(title_text=\"KB/s\", row=row, col=col)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Network Throughput per Client (RX vs TX)\",\n",
    "        height=270 * n_rows,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_bytes_per_sec(val: float) -> str:\n",
    "    \"\"\"Format bytes/s to human-readable units.\"\"\"\n",
    "    for unit in [\"B/s\", \"KB/s\", \"MB/s\", \"GB/s\"]:\n",
    "        if abs(val) < 1024:\n",
    "            return f\"{val:.1f} {unit}\"\n",
    "        val /= 1024\n",
    "    return f\"{val:.1f} TB/s\"\n",
    "\n",
    "\n",
    "# Combine all networking metrics into a summary\n",
    "all_clients = sorted(set(\n",
    "    list(peers_df[\"client\"].unique())\n",
    "    + list(att_df[\"client\"].unique())\n",
    "))\n",
    "\n",
    "summary_rows = []\n",
    "for client in all_clients:\n",
    "    row = {\"Client\": client}\n",
    "\n",
    "    # Peers\n",
    "    client_peers = peers_df[peers_df[\"client\"] == client][\"value\"]\n",
    "    if not client_peers.empty:\n",
    "        row[\"Avg Peers\"] = f\"{client_peers.mean():.1f}\"\n",
    "        row[\"Min Peers\"] = f\"{client_peers.min():.0f}\"\n",
    "\n",
    "    # Attestations\n",
    "    client_att = att_df[att_df[\"client\"] == client]\n",
    "    valid = client_att[client_att[\"metric\"] == \"lean_attestations_valid_total\"][\"value\"].max()\n",
    "    invalid = client_att[client_att[\"metric\"] == \"lean_attestations_invalid_total\"][\"value\"].max()\n",
    "    if pd.notna(valid):\n",
    "        row[\"Valid Atts\"] = f\"{valid:.0f}\"\n",
    "    if pd.notna(invalid) and invalid > 0:\n",
    "        row[\"Invalid Atts\"] = f\"{invalid:.0f}\"\n",
    "\n",
    "    # Network bandwidth\n",
    "    container_name = f\"{client}_0\"\n",
    "    if not net_df.empty:\n",
    "        cnet = net_df[net_df[\"container\"] == container_name]\n",
    "        rx = cnet[cnet[\"metric\"] == \"rx\"][\"value\"]\n",
    "        tx = cnet[cnet[\"metric\"] == \"tx\"][\"value\"]\n",
    "        if not rx.empty:\n",
    "            row[\"Avg RX\"] = format_bytes_per_sec(rx.mean())\n",
    "        if not tx.empty:\n",
    "            row[\"Avg TX\"] = format_bytes_per_sec(tx.mean())\n",
    "\n",
    "    summary_rows.append(row)\n",
    "\n",
    "if summary_rows:\n",
    "    summary_df = pd.DataFrame(summary_rows).set_index(\"Client\").fillna(\"-\")\n",
    "    display(summary_df)\n",
    "\n",
    "print(f\"\\nDevnet: {devnet_id}\")\n",
    "if devnet_info:\n",
    "    print(f\"Duration: {devnet_info['duration_hours']:.1f} hours\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
