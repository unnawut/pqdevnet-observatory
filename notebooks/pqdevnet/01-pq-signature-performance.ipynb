{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Quantum Signature Performance\n",
    "\n",
    "Analysis of post-quantum cryptographic signature performance in Lean Consensus clients.\n",
    "\n",
    "This notebook examines:\n",
    "- Attestation signing time (p50, p95, p99)\n",
    "- Attestation verification time\n",
    "- Aggregate signature building and verification\n",
    "- Performance comparison across clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters - injected by papermill\n",
    "devnet_id = None  # e.g., \"devnet-003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set default renderer for static HTML output\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve devnet_id\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "if devnet_id is None:\n",
    "    # Use latest devnet from manifest\n",
    "    devnets_path = DATA_DIR / \"devnets.json\"\n",
    "    if devnets_path.exists():\n",
    "        with open(devnets_path) as f:\n",
    "            devnets = json.load(f).get(\"devnets\", [])\n",
    "        if devnets:\n",
    "            devnet_id = devnets[-1][\"id\"]  # Latest\n",
    "            print(f\"Using latest devnet: {devnet_id}\")\n",
    "    else:\n",
    "        raise ValueError(\"No devnets.json found. Run 'just detect-devnets' first.\")\n",
    "\n",
    "DEVNET_DIR = DATA_DIR / devnet_id\n",
    "print(f\"Loading data from: {DEVNET_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load devnet metadata\n",
    "with open(DATA_DIR / \"devnets.json\") as f:\n",
    "    devnets_data = json.load(f)\n",
    "    devnet_info = next((d for d in devnets_data[\"devnets\"] if d[\"id\"] == devnet_id), None)\n",
    "\n",
    "if devnet_info:\n",
    "    print(f\"Devnet: {devnet_info['id']}\")\n",
    "    print(f\"Duration: {devnet_info['duration_hours']:.1f} hours\")\n",
    "    print(f\"Time: {devnet_info['start_time']} to {devnet_info['end_time']}\")\n",
    "    print(f\"Slots: {devnet_info['start_slot']} â†’ {devnet_info['end_slot']}\")\n",
    "    print(f\"Clients: {', '.join(devnet_info['clients'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PQ signature timing data\n",
    "timing_df = pd.read_parquet(DEVNET_DIR / \"pq_signature_timing.parquet\")\n",
    "print(f\"Loaded {len(timing_df)} timing records\")\n",
    "print(f\"Metrics: {timing_df['metric'].unique().tolist()}\")\n",
    "print(f\"Clients: {timing_df['client'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PQ signature counts\n",
    "counts_df = pd.read_parquet(DEVNET_DIR / \"pq_signature_metrics.parquet\")\n",
    "print(f\"Loaded {len(counts_df)} count records\")\n",
    "print(f\"Metrics: {counts_df['metric'].unique().tolist()}\")\n",
    "\n",
    "# Unified client list from devnet metadata (includes all containers via cAdvisor)\n",
    "all_clients = sorted(devnet_info[\"clients\"])\n",
    "n_cols = min(len(all_clients), 2)\n",
    "n_rows = -(-len(all_clients) // n_cols)\n",
    "print(f\"\\nAll clients ({len(all_clients)}): {all_clients}\")\n",
    "\n",
    "# Overall time range for empty chart placeholders\n",
    "all_ts = pd.concat([timing_df[\"timestamp\"], counts_df[\"timestamp\"]])\n",
    "t_min, t_max = all_ts.min(), all_ts.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attestation Signing Time\n",
    "\n",
    "How long does it take to sign an attestation using post-quantum cryptography?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to signing time metric\n",
    "signing_df = timing_df[timing_df[\"metric\"] == \"signing\"].copy()\n",
    "\n",
    "if signing_df.empty:\n",
    "    print(\"No signing time data available\")\n",
    "else:\n",
    "    # Convert to milliseconds for readability\n",
    "    signing_df[\"value_ms\"] = signing_df[\"value\"] * 1000\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=n_rows, cols=n_cols,\n",
    "        subplot_titles=all_clients,\n",
    "        vertical_spacing=0.12 / max(n_rows - 1, 1) * 2,\n",
    "        horizontal_spacing=0.08,\n",
    "    )\n",
    "\n",
    "    colors = {\"0.5\": \"#636EFA\", \"0.95\": \"#EF553B\", \"0.99\": \"#00CC96\"}\n",
    "    legend_added = set()\n",
    "\n",
    "    for i, client in enumerate(all_clients):\n",
    "        row = i // n_cols + 1\n",
    "        col = i % n_cols + 1\n",
    "        cdf = signing_df[signing_df[\"client\"] == client]\n",
    "        if cdf.empty:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=[t_min, t_max], y=[0, 0], name=client, showlegend=False, line=dict(color=\"#636EFA\")),\n",
    "                row=row, col=col,\n",
    "            )\n",
    "        else:\n",
    "            for q in sorted(cdf[\"quantile\"].unique()):\n",
    "                qdf = cdf[cdf[\"quantile\"] == q].sort_values(\"timestamp\")\n",
    "                q_str = str(q)\n",
    "                label = f\"p{int(q * 100)}\"\n",
    "                show_legend = q_str not in legend_added\n",
    "                legend_added.add(q_str)\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=qdf[\"timestamp\"], y=qdf[\"value_ms\"],\n",
    "                        name=label, legendgroup=q_str,\n",
    "                        showlegend=show_legend,\n",
    "                        line=dict(color=colors.get(q_str, \"#AB63FA\")),\n",
    "                    ),\n",
    "                    row=row, col=col,\n",
    "                )\n",
    "        fig.update_yaxes(title_text=\"ms\", row=row, col=col)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Attestation Signing Time by Client\",\n",
    "        height=270 * n_rows,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by client\n",
    "if not signing_df.empty:\n",
    "    summary = signing_df.groupby([\"client\", \"quantile\"])[\"value_ms\"].agg([\"mean\", \"min\", \"max\"]).round(3)\n",
    "    summary.columns = [\"Mean (ms)\", \"Min (ms)\", \"Max (ms)\"]\n",
    "    display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attestation Verification Time\n",
    "\n",
    "How long does it take to verify an attestation signature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to verification time metric\n",
    "verification_df = timing_df[timing_df[\"metric\"] == \"verification\"].copy()\n",
    "\n",
    "if verification_df.empty:\n",
    "    print(\"No verification time data available\")\n",
    "else:\n",
    "    verification_df[\"value_ms\"] = verification_df[\"value\"] * 1000\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=n_rows, cols=n_cols,\n",
    "        subplot_titles=all_clients,\n",
    "        vertical_spacing=0.12 / max(n_rows - 1, 1) * 2,\n",
    "        horizontal_spacing=0.08,\n",
    "    )\n",
    "\n",
    "    colors = {\"0.5\": \"#636EFA\", \"0.95\": \"#EF553B\", \"0.99\": \"#00CC96\"}\n",
    "    legend_added = set()\n",
    "\n",
    "    for i, client in enumerate(all_clients):\n",
    "        row = i // n_cols + 1\n",
    "        col = i % n_cols + 1\n",
    "        cdf = verification_df[verification_df[\"client\"] == client]\n",
    "        if cdf.empty:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=[t_min, t_max], y=[0, 0], name=client, showlegend=False, line=dict(color=\"#636EFA\")),\n",
    "                row=row, col=col,\n",
    "            )\n",
    "        else:\n",
    "            for q in sorted(cdf[\"quantile\"].unique()):\n",
    "                qdf = cdf[cdf[\"quantile\"] == q].sort_values(\"timestamp\")\n",
    "                q_str = str(q)\n",
    "                label = f\"p{int(q * 100)}\"\n",
    "                show_legend = q_str not in legend_added\n",
    "                legend_added.add(q_str)\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=qdf[\"timestamp\"], y=qdf[\"value_ms\"],\n",
    "                        name=label, legendgroup=q_str,\n",
    "                        showlegend=show_legend,\n",
    "                        line=dict(color=colors.get(q_str, \"#AB63FA\")),\n",
    "                    ),\n",
    "                    row=row, col=col,\n",
    "                )\n",
    "        fig.update_yaxes(title_text=\"ms\", row=row, col=col)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Attestation Verification Time by Client\",\n",
    "        height=270 * n_rows,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Signature Performance\n",
    "\n",
    "Time to build and verify aggregated signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to aggregate metrics\n",
    "agg_metrics = [\"agg_building\", \"agg_verification\"]\n",
    "agg_df = timing_df[timing_df[\"metric\"].isin(agg_metrics)].copy()\n",
    "\n",
    "if agg_df.empty:\n",
    "    print(\"No aggregate signature timing data available\")\n",
    "else:\n",
    "    agg_df[\"value_ms\"] = agg_df[\"value\"] * 1000\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=n_rows, cols=n_cols,\n",
    "        subplot_titles=all_clients,\n",
    "        vertical_spacing=0.12 / max(n_rows - 1, 1) * 2,\n",
    "        horizontal_spacing=0.08,\n",
    "    )\n",
    "\n",
    "    colors = {\"agg_building\": \"#636EFA\", \"agg_verification\": \"#EF553B\"}\n",
    "    legend_added = set()\n",
    "\n",
    "    for i, client in enumerate(all_clients):\n",
    "        row = i // n_cols + 1\n",
    "        col = i % n_cols + 1\n",
    "        cdf = agg_df[agg_df[\"client\"] == client]\n",
    "        if cdf.empty:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=[t_min, t_max], y=[0, 0], name=client, showlegend=False, line=dict(color=\"#636EFA\")),\n",
    "                row=row, col=col,\n",
    "            )\n",
    "        else:\n",
    "            for metric in agg_metrics:\n",
    "                mdf = cdf[cdf[\"metric\"] == metric]\n",
    "                if mdf.empty:\n",
    "                    continue\n",
    "                label = metric.replace(\"agg_\", \"\")\n",
    "                show_legend = metric not in legend_added\n",
    "                legend_added.add(metric)\n",
    "                fig.add_trace(\n",
    "                    go.Box(\n",
    "                        y=mdf[\"value_ms\"],\n",
    "                        name=label, legendgroup=metric,\n",
    "                        showlegend=show_legend,\n",
    "                        marker_color=colors[metric],\n",
    "                    ),\n",
    "                    row=row, col=col,\n",
    "                )\n",
    "        fig.update_yaxes(title_text=\"ms\", row=row, col=col)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Aggregate Signature Timing by Client\",\n",
    "        height=270 * n_rows,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Comparison: P95 Signing Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare p95 signing time across clients\n",
    "p95_signing = signing_df[signing_df[\"quantile\"] == 0.95].copy() if not signing_df.empty else pd.DataFrame()\n",
    "\n",
    "if p95_signing.empty:\n",
    "    print(\"No p95 signing data available\")\n",
    "else:\n",
    "    fig = px.bar(\n",
    "        p95_signing.groupby(\"client\")[\"value_ms\"].mean().reset_index(),\n",
    "        x=\"client\",\n",
    "        y=\"value_ms\",\n",
    "        title=\"Average P95 Attestation Signing Time by Client\",\n",
    "        labels={\n",
    "            \"value_ms\": \"P95 Signing Time (ms)\",\n",
    "            \"client\": \"Client\",\n",
    "        },\n",
    "        color=\"client\",\n",
    "    )\n",
    "    fig.update_layout(height=400, showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signature Success Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate valid/invalid signature rates\n",
    "valid_df = counts_df[counts_df[\"metric\"] == \"lean_pq_sig_aggregated_signatures_valid_total\"]\n",
    "invalid_df = counts_df[counts_df[\"metric\"] == \"lean_pq_sig_aggregated_signatures_invalid_total\"]\n",
    "\n",
    "if valid_df.empty and invalid_df.empty:\n",
    "    print(\"No signature count data available\")\n",
    "else:\n",
    "    # Get final counts per client\n",
    "    def get_final_count(df):\n",
    "        if df.empty:\n",
    "            return pd.DataFrame()\n",
    "        return df.groupby(\"client\")[\"value\"].max().reset_index()\n",
    "    \n",
    "    valid_final = get_final_count(valid_df)\n",
    "    invalid_final = get_final_count(invalid_df)\n",
    "    \n",
    "    if not valid_final.empty:\n",
    "        valid_final[\"status\"] = \"valid\"\n",
    "    if not invalid_final.empty:\n",
    "        invalid_final[\"status\"] = \"invalid\"\n",
    "    \n",
    "    combined = pd.concat([valid_final, invalid_final], ignore_index=True)\n",
    "    \n",
    "    if not combined.empty:\n",
    "        fig = px.bar(\n",
    "            combined,\n",
    "            x=\"client\",\n",
    "            y=\"value\",\n",
    "            color=\"status\",\n",
    "            barmode=\"group\",\n",
    "            title=\"Aggregated Signature Counts by Client\",\n",
    "            labels={\n",
    "                \"value\": \"Count\",\n",
    "                \"client\": \"Client\",\n",
    "                \"status\": \"Status\",\n",
    "            },\n",
    "            color_discrete_map={\"valid\": \"#2ecc71\", \"invalid\": \"#e74c3c\"},\n",
    "        )\n",
    "        fig.update_layout(height=400)\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key findings from this devnet iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics\n",
    "print(f\"Devnet: {devnet_id}\")\n",
    "print(f\"Duration: {devnet_info['duration_hours']:.1f} hours\")\n",
    "print(f\"Clients analyzed: {len(timing_df['client'].unique())}\")\n",
    "print()\n",
    "\n",
    "if not signing_df.empty:\n",
    "    p95_mean = signing_df[signing_df[\"quantile\"] == 0.95][\"value_ms\"].mean()\n",
    "    print(f\"Average P95 signing time: {p95_mean:.2f} ms\")\n",
    "\n",
    "if not verification_df.empty:\n",
    "    p95_ver = verification_df[verification_df[\"quantile\"] == 0.95][\"value_ms\"].mean()\n",
    "    print(f\"Average P95 verification time: {p95_ver:.2f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
